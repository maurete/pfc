function [svm_params, out, paramh, errh, ntrain] = select_model_rmb ( ...
    problem, feats, kernel, lib, theta0, gtol, max_iter, Delta )
%SELECT_MODEL_RMB Select L1-SVM-RBF model with Radius Margin Bound-like method
%
%  [SVM_PARAMS,MODEL,PARAMH,ERRH,NTRAIN] = SELECT_MODEL_RMB(PROBLEM, ...
%      FEATS, KERNEL, LIB, THETA0, GTOL, MAX_ITER, DELTA) performs model
%  selection for L1-SVM with RBF kernel by minimizing the ERROR_RMB_CSVM
%  objective function with the OPT_BFGS optimization method.
%  Input arguments, (*)=optional:
%    PROBLEM the problem with trained data generated by PROBLEM_GEN
%    FEATS the featureset index, commonly 5 or 8
%    KERNEL a string with value 'linear' for linear kernel or 'rbf' for RBF
%    LIB the SVM library to be used, either 'libsvm' or 'matlab'
%    THETA0 (*) starting value for the SVM params
%    GTOL (*) precision for calculations in ERROR_RMB_CSVM
%    MAX_ITER (*) maximum number of iterations for the BFGS algorithm
%    DELTA (*) Delta parameter for the RMB function (default=1)
%  Output arguments:
%    SVM_PARAMS the optimal SVM parameters found
%    MODEL the optimal trained model
%    PARAMH the parameter history for each iteration
%    ERRH the objective function value in each iteration
%    NTRAIN the number of SVM trainings performed
%
%  The 'RMB' method is taken from Chung Chung et al., "Radius Margin Bounds
%  for Support Vector Machines with the RBF kernel" (2002)
%
%  See also PROBLEM_GEN, SELECT_MODEL, ERROR_RMB_CSVM.
%

    features = featset_index(feats);
    kernel = get_kernel(kernel);
    svm_tol = 1e-6;

    % default parameter values
    if nargin < 8 || isempty(Delta),    Delta    = 1; end
    if nargin < 7 || isempty(max_iter), max_iter = 100; end
    if nargin < 6 || isempty(gtol),     gtol     = 1e-3; end

    % initial parameter vector
    if nargin > 4 && ~isempty(theta0), theta = theta0;
    elseif get_kernel(kernel,'rbf',false), theta = [0 0];
    else theta = 0;
    end

    time = time_init();
    time = time_tick(time, 1);

    % training function
    trainfunc = @(input,target,theta) mysvm_train( ...
        lib, kernel, input, target, theta(1), theta(2:end), false, svm_tol );

    % error/objective function
    rmb_func = @(theta) error_rmb_csvm( ...
        trainfunc, exp(theta), Delta, true, problem.traindata(:,features), ...
        problem.trainlabels );

    % optimization function
    [svm_params,~,paramh,errh,ntrain] = opt_bfgs(rmb_func, false, theta, ...
                                                 gtol, max_iter );

    % Build output model
    out = struct();
    out.features = features;
    out.trainfunc = func2str(@(in,tg) mysvm_train( lib, kernel, in, tg, ...
            exp(svm_params(1)), exp(svm_params(2:end)), false, svm_tol ));
    out.trainfuncargs = struct();
    out.trainfuncargs.lib = lib;
    out.trainfuncargs.kernel = kernel;
    out.trainfuncargs.svm_params = svm_params;
    out.trainfuncargs.svm_tol = svm_tol;
    out.classfunc = 'mysvm_classify';
    out.trainedmodel = mysvm_train( lib, kernel, problem.traindata(:,features), ...
                                    problem.trainlabels, exp(svm_params(1)), ...
                                    exp(svm_params(2:end)), false, svm_tol );

    time = time_tick(time, 1);
    ntrain = ntrain + 1;

end
