\documentclass[12pt,bibliography=oldstyle,DIV=12,parskip=half-,titlepage]{scrartcl}
\include{conf/preconfig}
\include{conf/packages}
\include{conf/config}
\include{conf/comandos}
\include{conf/fuentes}
%
\addbibresource{res/bibliografia.bib}
%
\selectlanguage{spanish}
\hyphenation{micro-RNA}
\hyphenation{micro-RNAs}
\hyphenation{mi-RNA}
\hyphenation{mi-RNAs}
%
%
%
%
\addtokomafont{descriptionlabel}{\small}
\setkomafont{subject}{\LARGE\usekomafont{disposition}}
\setkomafont{title}{\normalfont\slshape}
\setkomafont{subtitle}{\LARGE\usekomafont{disposition}}
%
\begin{document}
\selectlanguage{spanish}
%
% pagina de titulo
%
\titlehead{\center\large
    Universidad Nacional del Litoral\\
    Facultad de Ingeniería y Ciencias Hídricas
}
%
%
\title{\LARGE ``Desarrollo de un clasificador de secuencias de pre-microRNA
  mediante técnicas de Inteligencia Computacional''}
\subject{Proyecto Final de Carrera\\Ingeniería en
  Informática}
\subtitle{~\\[.2ex]Informe entregable 2\\[.2ex]~}
\author{{Alumno: Mauro Javier Torrez}\and{Director: Dr. Diego H. Milone}}
%
\date{~\\[2em]\today}
%
\renewcommand*{\titlepagestyle}{empty}
%\thispagestyle{empty}
\maketitle
\setcounter{page}{1}
%
%
%
%
\section{Introducción}
\resalt{\Large texto introductorio}

%% Se realizaron pruebas de clasificación con clasificadores SVM y MLP,
%% variando los parámetros de cada uno, para distintas configuraciones de
%% datos de entrenamiento/prueba y de conjuntos de características
%% utilizados.

\section{Clasificadores}
%% Para las pruebas se utilizaron clasificadores SVM y MLP según se
%% detallan a continuación.

\subsection{SVM}
Se seleccionaron para el clasificador SVM dos \eng{kernels}
\cite{bottou} diferentes, lineal (SVM-LINEAR) y función de base radial
(SVM-RBF).  \resalt{Explicar.}

Se implementó para SVM-RBF un algoritmo de búsqueda de parámetros
óptimos de tipo \emph{búsqueda en la grilla} (\eng{grid-search}) \cite{hsu}.
Este algoritmo consiste en, a partir de valores iniciales para los
parámetros $C$ y $\sigma$ del clasificador, en cada iteración se
genera un nuevo conjunto de parámetros en las cercanías de aquellos
que obtienen el mejor rendimiento. \resalt{Mejorar.}

Se realizaron las pruebas con cuatro etapas de refinamiento de los
parámetros, partiendo de una grilla logarítmicamente espaciada en
$10^2$ se llega a una grilla refinada en $10^{0.25}$ con una
progresión de $10^{(2-r)}$, con $r$ el número de iteración.

Para el clasificador SVM-LINEAR se implementó un algoritmo de búsqueda
del parámetro óptimo muy similar al de búsqueda en la grilla, en este
caso para el parámetro único $C$.

%% \begin{algorithm}[H]
%% %% \SetKwInput{Datos}{Datos}
%% %% \SetKwInput{Resultado}{Resultado}
%% %% \SetKwInput{Entrada}{Entrada}
%% %% \SetKwInput{Salida}{Salida}
%% %% \SetKw{KwA}{a}
%% %% \SetKw{KwDevolver}{devolver}
%% %% \SetKw{Devolver}{devolver}
%% %% \SetKwBlock{Inicio}{inicio}{fin}
%% %% \SetKwIF{SSi}{EnOtroCasoSi}{EnOtroCaso}{si}{entonces}{sin\'o, si}{sin\'o}{fin si}
%% %% \SetKwSwitch{Seleccionar}{Caso}{Otro}{seleccionar}{hacer}{caso}{sin\'o}{fin caso}{fin seleccionar}
%% %% \SetKwFor{Para}{para}{hacer}{fin para}
%% %% \SetKwFor{ParaPara}{par}{hacer en paralelo}{fin para}
%% %% \SetKwFor{EnParalelo}{para}{hacer en paralelo}{fin para}
%% %% \SetKwFor{Mientras}{mientras}{hacer}{fin mientras}
%% %% \SetKwFor{ParaCada}{para cada}{hacer}{fin para cada}
%% %% \SetKwFor{ParaTodo}{para todo}{hacer}{fin para todo}
%% %% \SetKwRepeat{Repetir}{repetir}{hasta que}
%% \SetAlgoLined
%% \Entrada{clasificador RBF, datos, $\sigma_0$, $C_0$, $R$}
%% \Resultado{$\sigma_{ni},C_{nj} | G_m(\T{Se}(\sigma_{ki},C_{kj}),\T{Sp}(\sigma_{ki},C_{kj})) = \max(G_m) \forall k,i,j$}
%% $C\leftarrow C_0$\;
%% $sigma\leftarrow\sigma_0$\;
%% \Para{$r\in [1,R]$}{ 
%% \ParaCada{$C_l, \sigma_m$}{
%% Se$_k$, Sp$_k$ $\leftarrow$ entrenar($C_l$, $\sigma_m$, datos, \ldots) \; 
%% $G_m(k)\leftarrow\sqrt{\T{Se}_k\cdot\T{Sp}_k}$
%% }
%% $G_m*\leftarrow\{G_m(k):(G_m(k)-\max(Gm(k)))<\T{tolerancia}\}$
%% }
%% \caption{How to write algorithms}
%% \end{algorithm}

\subsection{MLP}
\resalt{\Large explicar mejor esta sección}

Se probaron clasificadores MLP con una topología \emph{capa de
  entrada} $\rightarrow$ \emph{capa oculta} $\rightarrow$ \emph{capa
  de salida}. Se probaron distintos valores en el rango $[5,25]$ para
el número de neuronas en la capa oculta.

Se utilizó para el clasificador MLP la implementación disponible en el
\eng{Neural Network Toolbox} del software MATLAB \resalt{ref.}.  Se
utilizó el método \mono{trainscg} como función de entrenamiento, el
cual utiliza el método del gradiente conjugado escalado \resalt{ref},
limitando el tiempo de entrenamiento por época a 10 segundos
\resalt{porqué?}, y estableciendo un número máximo de épocas de
$2\cdot10^{12}$.
%
\section{Conjuntos de datos}
Se generaron 5 configuraciones diferentes para los conjuntos de datos, 
cada una de las cuales especifica los conjuntos de la base de datos 
utilizados tanto para entrenamiento como para prueba.

En la tabla \ref{datasetup} se detallan los conjuntos utilizados en
cada configuración.  A continuación se describen cada una de las
configuraciones.

En el caso de la base de datos \sbs{mirbase20}, se aplicó el algoritmo
de filtrado CD-HIT \cite{greedy} con parámetros por
defecto. \resalt{aclarar bien: xue, ng y batuwita hicieron lo mismo.}

%
\begin{table}[H]
  \caption{Configuraciones de los conjuntos de datos utilizados para las pruebas}
  \center%\sffamily
  \begin{tabular}{llrlrrrr}\toprule
Config. &
Fuente             & Clase & Especies  & Total  & Train & Test  \\\midrule
\mrow{4}{*}{HSA}
& mirbase20        & +1    & humano    & 1265   & 1200  & 65    \\
& coding           & -1    & humano    & 8494   & 2271  & 6223  \\
& other-ncrna      & -1    & humano    & 129    & 129   & 0     \\
& mirbase20        & +1    & no humano & 11805  & 0     & 11805 \\\midrule
\mrow{4}{*}{ALL}
& mirbase20        & +1    & todas     & 13070  & 2200  & 10870 \\
& functional-ncrna & -1    & varias    & 2650   & 2200  & 450   \\
& coding           & -1    & humano    & 8494   & 0     & 8494  \\
& other-ncrna      & -1    & humano    & 129    & 0     & 129   \\\midrule
\mrow{7}{*}{XUE}
& mirbase50        & +1    & humano    & 193    & 163   &  30   \\
& coding           & -1    & humano    & 8494   & 168   & 1000  \\
& conserved-hairpin& -1?   & humano    & 2444   & 0     & 2444  \\
& updated          & +1    & humano    & 39     & 0     &  39   \\
& mirbase50        & +1    & no-humano & 1017   & 0     & 1017  \\
& mirbase20        & +1    & humano    & 1265   & 0     & 1265  \\
& mirbase20        & +1    & no-humano & 11805  & 0     & 11805 \\\midrule
\mrow{7}{*}{NG}
& mirbase82        & +1    & humano    & 308    & 200   & 108   \\
& coding           & -1    & humano    & 8494   & 400   & 8094  \\
& mirbase82        & +1    & no-humano & 1677   & 0     & 1677  \\
& functional-ncrna & -1    & varias    & 2650   & 0     & 2650  \\
& mirbase20        & +1    & humano    & 1265   & 0     & 1265  \\
& mirbase20        & +1    & no-humano & 11805  & 0     & 11805 \\\midrule
\mrow{5}{*}{BTW}
& mirbase12        & +1    & humano    & 660    & 561   & 99    \\
& coding           & -1    & humano    & 8494   & 1012  & 7482  \\
& other-ncrna      & -1    & humano    & 129    & 110   & 19    \\
& mirbase20        & +1    & humano    & 1265   & 0     & 1265  \\
& mirbase20        & +1    & no-humano & 11805  & 0     & 11805 \\
\bottomrule
  \end{tabular}
  \label{datasetup}
\end{table}
%
\subsection{Configuración HSA}
En esta configuración se utilizan para entrenamiento 1200 entradas del
conjunto de datos positivo \sbs{mirbase20} (humano), y 2400 entradas
de los conjuntos de datos negaivos \sbs{other-ncrna} (humano), y
\sbs{coding} (humano).

El clasificador se evalúa contra las 65 entradas restantes de humanos
de \sbs{mirbase20}, contra otras 6223 del conjunto negativo
\sbs{coding}, y contra las 11805 entradas de \sbs{mirbase20} que no
pertenecen a humanos.
%
\subsection{Configuración ALL}
En esta configuración se utilizan como datos de entrenamiento positivo
2200 entradas del conjunto \sbs{mirbase20} para todas las especies,
tomadas aleatoriamente. Como entrenamiento negativo, se utilizan 2200
entradas del conjunto \sbs{functional-ncrna}, que contiene ncRNAs
funcionales (exceptuando pre-miRNAs) para todas las especies.

El clasificador de prueba contra las 10870 entradas restantes de
\sbs{mirbase20}, discriminando entre entradas de humano/no-humano,
contra las 450 entradas de \sbs{functional-ncrna} no utilizadas para
entrenamiento, y contra las bases de datos negativas \sbs{coding}
(humano) y \sbs{other-ncrna} (humano).
%
\subsection{Configuración XUE}
En esta configuración se replican los conjuntos de entrenamiento y
prueba utilizados en \cite{xue}: entrenamiento con 163 entradas de
humanos de \sbs{mirbase50} y 168 de \sbs{coding}, y prueba contra
\sbs{mirbase50} (30 entradas de humanos, 1017 otras especies),
\sbs{coding} (1000 entradas de humanos), \sbs{conserved-hairpin} (2444
entradas de humanos) y \sbs{updated} (39 entradas humanos).

Se prueba además el clasificador contra la base de datos positiva
\sbs{mirbase20} discriminando entre entradas pertenecientes a humanos
y a otras especies.
%
\subsection{Configuración NG}
En esta configuración se replican los conjuntos de datos utilizados en
\cite{ng}.  Para entrenamiento se utilizan 200 entradas del conjunto
positivo \sbs{mirbase82} y 400 del conjunto negativo \sbs{coding}.

Se prueba el clasificador con las 108 entradas de humanos restantes de
\sbs{mirbase82}, 8094 de \sbs{coding}, 1677 entradas de
\sbs{mirbase82} pertenecientes a otras especies, 2650 entradas
negativas del conjunto \sbs{functional-ncrna}, además de las 13070
entradas del conjunto positivo \sbs{mirbase20} discriminando entre
humano y otras especies.
%
\subsection{Configuración BTW}
Se entrena utilizando los conjuntos de datos utilizados en
\cite{batuwita}, tomando como conjunto positivo el 85\% (561) de las
entradas de humanos disponibles en \sbs{mirbase12}, y como conjunto de
datos negativos se toman 1122 entradas de los conjuntos \sbs{coding}
(1012) y \sbs{other-ncrna} (110).

Se prueba el clasificador con las entradas restantes de los conjuntos
utilizados para entrenamiento: \sbs{mirbase12} (99), \sbs{coding}
(7482) y \sbs{other-ncrna} (19), además de las 13070 disponibles en
\sbs{mirbase20} discriminando entre humano y no-humano.
%


\section{Conjuntos de características}
Considerando los conjuntos de características definidos en la etapa anterior,
se probaron 15 configuraciones diferentes que abarcan todas las combinaciones
posibles. La composición de cada configuración se muestra en la Tabla
\ref{featsets}, marcando con un asterisco (*) el conjunto incluido en la respectiva configuración.

\begin{table}[H]
  \caption{Configuraciones de prueba para las características.}
  \center%\sffamily
  \begin{tabular}{lccccccccccccccc}\toprule
Características / Configuración & 1& 2& 3& 4& 5& 6& 7& 8& 9&10&11&12&13&14&15\\
\midrule
Tripletes                       & *& *&  &  &  & *& *&  & *&  &  &  & *& *& *\\
Tripletes ``extra''             & *&  & *&  &  & *& *&  & *& *& *& *&  &  &  \\
Medidas de la secuencia         & *&  &  & *&  &  &  & *& *& *&  & *&  & *& *\\
Medidas estructura secundaria   & *&  &  &  & *&  & *& *&  & *& *&  & *&  & *\\
\bottomrule
  \end{tabular}
  \label{featsets}
\end{table}


\section{Pruebas de clasificación}

Las pruebas de clasificación se realizaron con los tres
clasificadores, para todas las combinaciones de configuraciones de los
conjuntos de datos y de los conjuntos de características.

Como medida para el rendimiento de los diferentes clasificadores se
utilizó la media geométrica entre la sensibilidad (tasa de
clasificación del conjunto de datos positivo) y la especificidad (tasa
de clasificación del conjunto de datos negativo) obtenida en cada
prueba.

Para cada cada prueba, el conjunto de datos de entrenamiento se
particionó en 5, 80\% entrenamiento y 20\% prueba (validación
cruzada), tal que cada conjunto de prueba no contenga entradas en
común con los otros 4. Se repitió el entrenamiento/validación cruzada
para las 5 particiones, y el resultado de la prueba se consideró como
la media aritmética de los 5 resultados obtenidos.

En pos de hacer que las pruebas fueran reproducibles, se utilizaron funciones pseudoaleatorias
que reciben como parámetro una \emph{semilla} para la generación de particiones
y el muestreo de las bases de datos. \resalt{explicar mejor.}


\section{Resultados de las pruebas de clasificación}
\resalt{Muy preliminar. Algunas conclusiones.}
\begin{itemize}
\item Dataset ALL: tasa muy baja para CODING. Se deberá reemplazar por otro dataset que entrene también con CODING.
\item Featureset 2 (triplet): no funciona bien para mirbase20.
\item Dataset XUE: rendimiento SVM-LINEAR igual o mejor que SVM-RBF.
\item Featureset 5 (estructura secundaria): muy buen desempeño con un vector de sólo 7 características.
\item Featureset 4 (secuencia): mejor desempeño que FS-5 únicamente en dataset ALL (que no funciona para CODING).
\item Dataset HSA: prácticamente clasifican mejor aquellos featuresets que excluyen los triplets.
\end{itemize}

\renewcommand{\bibfont}{\normalfont\footnotesize}
\printbibliography
\end{document}


\subsubsection{Características de tripletes}
Vector de 32 elementos de tripletes, calculado según \cite{xue}.
Considerando la región del tallo, contiene el número de ocurrencias
del elemento triplete correspondiente, normalizado entre el número
total de ocurrencias.  El orden es el siguiente: \mono{A..., A..(,
  A.(., A.((, A(.., A(.(, A((., A(((, G..., G..(, G.(., G.((, G(..,
  G(.(, G((., G(((, C..., C..(, C.(., C.((, C(.., C(.(, C((., C(((,
  U..., U..(, U.(., U.((, U(.., U(.(, U((., U(((}.
%
\subsubsection{Características de tripletes ``extra''}
Características auxiliares que se obtienen
al calcular el vector de tripletes.
\begin{description}[style=sameline,leftmargin=3cm]
\item[length3] longitud de la secuencia considerada al
  extraer los elementos de triplete (número de bases que
  conforman el tallo de la estructura de horquilla).
\item[basepairs] número de pares de bases en
  el pre-miRNA.
\item[{length3/basepairs}] grado de complementariedad
  entre los dos brazos de la estructura de horquilla. Para una
  complementariedad perfecta se da el valor mínimo de 2, aumentando cuanto más
  bases ``sueltas'' contenga el tallo.
\item[gc\_content] $=(\T{cant(\mono{G})}+\T{cant(\mono{C})})/\mono{length3}$. Proporción de nucleótidos \mono{G} y
  \mono{C} en el tallo.
\end{description}
%
\subsubsection{Medidas de la secuencia}
%Este grupo contiene las siguientes medidas de la secuencia del pre-miRNA:
\begin{description}[style=sameline,leftmargin=3cm]
\item[length] longitud del pre-miRNA, incluyendo extremos sueltos y el
  bucle central.
\item[A, C, G, U] (x4) número de nucleótidos \mono{A}, \mono{C},
  \mono{G} y \mono{U}, respectivamente.
\item[G+C, A+U] (x2) número de nucleótidos \mono{G} y \mono{C}, y
  \mono{A} y \mono{U} respectivamente.
\item[XY] (x16) número de dinucleótidos (dos nucleótidos contiguos)
  \mono{XY}, con $\mono{X,Y}\in\{\mono{A,C,G,U}\}$. El orden es el
  siguiente: \mono{AC, AG, AU, CA, CC, CG, CU, GA, GC, GG, GU, UA, UC,
    UG, UU}.
\end{description}
%
\subsubsection{Medidas de la estructura secundaria}
%En este grupo se presentan las siguientes características relativas al
%plegado del pre-miRNA en su estructura de horquilla:
\begin{description}[style=sameline,leftmargin=3cm]
\item[MFE] Mínima Energía Libre obtenida al plegar la secuencia con
  \mono{RNAfold}.
\item[MFEI1] $={\mono{MFE}}/{(\mono{G+C})\cdot 100}$, con \mono{G+C}
  de las medidas de secuencia.
\item[MFEI4] $=\mono{MFE}/\mono{basepairs}$ con \mono{basepairs} de
  las características de triplete extra.
\item[dP] \mono{basepairs} normalizada con la longitud total
  \mono{length}.
\item[|A-U|/length] número de pares \mono{A-U} normalizado.
\item[|G-C|/length] número de pares \mono{G-C} normalizado.
\item[|G-U|/length] número de pares \mono{G-U} normalizado.
\end{description}


Para el entrenamiento y validación 


En la fase de pruebas se trabajará con dos conjuntos de datos diferentesgenerados a
partir 



Para las pruebas a realizar en esta etapa se procederá a la generación
de un conjunto de datos propio, a partir del conjunto de datos \sbs{mirbase20}
habiendo aplicado el algoritmo de \emph{clustering} \emph{CD-HIT}\resalt{ref},
y como conjuntos de datos negativos se utilizarán elementos de los conjuntos 
\sbs{coding, functional-ncrna, other-ncrna}.

\subsection*{Clasificadores}

svm -- grid search

mlp
\subsection*{Características}
todas las feats, discriminadas por clase
\subsection*{Configuración de las pruebas}
svm - grid search
mlp - no. de neuronas capa oculta
libsvm?
libfann?
\subsubsection*{XUE}
training, test
\subsubsection*{NG}
training,test
\subsubsection*{BTW}

training, test
\subsubsection*{OWN}
training, test

\subsection*{Resultados}

%\% aciertos

tiempos

Los clasificadores se entrenaron con el mismo conjunto de datos de
\cite{xue}, y se probaron con los conjuntos de prueba \emph{Real} (30
elementos), \emph{Pseudo} (1000 elementos) y \emph{Updated} (39
elementos), también de la misma fuente.

En el caso de SVM-Matlab y MLP, se probaron diversos parámetros hasta
encontrar aquellos que obtienen el mejor rendimiento del clasificador.
En la tabla \ref{testresults} se presentan figuras de rendimiento para
los distintos clasificadores. %En el caso de SVM-Matlab se muestran
%tres resultados representativos correspondientes a diferentes
%parámetros. 
En el caso MLP, se encontró que los resultados no varían
significativamente para distintas configuraciones, con diferencias
menores a 3\% en cada caso.  Se muestran entonces para MLP tasas
representativas.
%
\begin{table}
  \caption{Resultados de las pruebas iniciales de clasificación}
  \center%\sffamily
  \begin{tabular}{lrrr}\toprule
    Clasificador  & \% Real (/30) &
                     \% Pseudo (/1000) & \% Updated (/39) \\\midrule
    Triplet-SVM   &  $93.3$    & $88.1$     & $92.3$     \\
    SVM (libSVM)  & $100.0$    & $87.4$     & $92.3$     \\
    SVM (Matlab)  & $100.0$    & $91.2$     & $89.7$     \\
    %% svm (matlab,2) & $96.7$     & $96.6$     & $48.7$     \\
    %% svm (matlab,3) & $100.0$    & $86.4$     & $97.4$     \\
    MLP           &  $90.0$    & $85.0$     & $91.0$  \\\bottomrule
  \end{tabular}
  \label{testresults}
\end{table}
%

Como se puede observar en la tabla \ref{testresults}, las tasas de
clasificación para los distintos conjuntos resultan satisfactorias, e
incluso sensiblemente mejores a aquellas del trabajo original.  Sin
embargo, estos números deberán tomarse con cuidado, ya que han sido
obtenidos entrenando y validando con particiones estáticas, y podrían
ser resultado de un sobreentrenamiento para estos datos en
particular. Se observa también que el perceptrón multicapa presenta
una buena tasa de clasificación incluso cuando se trata de una única
neurona (sin capas ocultas), siempre para este mismo conjunto de
datos.

Se ha implementado el script \mono{triplet\_libsvm.sh} para las
pruebas con \emph{libsvm}, y los scripts \mono{triplet\_svm.m} y
\mono{triplet\_mlp.m} para las pruebas en Matlab de los clasificadores
SVM y MLP respectivamente. Con el software apropiado, estos scripts
se pueden ejecutar directamente para reproducir los resultados de las
pruebas.

%
%
%
%
%
\section{Armado de la base de datos definitiva}
Para el armado de la base de datos definitiva se tomaron como fuente
los conjuntos de datos y características utilizados en \cite{xue},
\cite{ng} y \cite{batuwita}. Se incorporó al conjunto de datos
la última versión disponible de miRBase \cite{mirbase}.

Como primer paso se procedió a validar el plegado de las secuencias en
las bases de datos originales aplicando el programa RNAfold sobre las
mismas y comprobando que el plegado obtenido fuera el mismo que el
presente en la base de datos original. Se utilizó la versión 1.8.5 de
RNAfold, ya que con la versión actual (2.1) se obtienen plegados
diferentes en la mayoría de los casos.

Una vez validadas las estructuras secundarias se procedió a filtrar
aquellas entradas con bucles múltiples en la estructura secundaria, ya
que las características de triplete no están definidas en estos casos.
De esta manera se eliminó la base de datos ``mRNA'' de \cite{ng} por
completo, ya que todas las entradas en este caso poseen bucles
múltiples.

Luego se procedió a la ectracción y validación de características
extraídas contra las bases de datos respectivas: las características
de triplete y triplete-extra contra la base de datos de \cite{xue},
las características de la secuencia contra la base de \cite{ng}, y las
de estructura secundaria con la base de datos en \cite{batuwita}.

Además de las características calculadas, se incorporan a la base de
datos los datos de la secuencia y estructura secundaria en formato
compatible RNAfold, junto con otro archivo donde se indica la clase
(pre-miRNA real, pseudo-pre-miRNA o indefinido) de cada entrada
correspondiente.  En el archivo \mono{README.md} de la base de datos
se detalla la estructura de directorios generada junto con el formato
de los archivos para cada caso.

Se codificó la herramienta \mono{feats.py} a partir de la utilidad
\mono{fautil.py}, para la extracción de características de archivos
con formato RNAfold. Se ignoraron aquellas características que no se
pueden calcular directamente con la información de la secuencia y de
la estructura secundaria.

Se codificó la herramienta \mono{tests.py} para la validación, así
como los scripts en Bash \mono{validate.sh} y \mono{generate\_db.sh},
los que pueden ser ejecutados directamente, siempre con el software
requerido, para validar y regenerar la misma base de datos a partir de
las fuentes.
%
\subsection{Características extraídas}
%
A continuación se enumeran las características disponibles en la base
de datos definitiva.
%
\subsubsection{Características de tripletes}
Vector de 32 elementos de tripletes, calculado según \cite{xue}.
Considerando la región del tallo, contiene el número de ocurrencias
del elemento triplete correspondiente, normalizado entre el número
total de ocurrencias.  El orden es el siguiente: \mono{A..., A..(,
  A.(., A.((, A(.., A(.(, A((., A(((, G..., G..(, G.(., G.((, G(..,
  G(.(, G((., G(((, C..., C..(, C.(., C.((, C(.., C(.(, C((., C(((,
  U..., U..(, U.(., U.((, U(.., U(.(, U((., U(((}.
%
\subsubsection{Características de tripletes ``extra''}
Características auxiliares que se obtienen
al calcular el vector de tripletes.
\begin{description}[style=sameline,leftmargin=3cm]
\item[length3] longitud de la secuencia considerada al
  extraer los elementos de triplete (número de bases que
  conforman el tallo de la estructura de horquilla).
\item[basepairs] número de pares de bases en
  el pre-miRNA.
\item[{length3/basepairs}] grado de complementariedad
  entre los dos brazos de la estructura de horquilla. Para una
  complementariedad perfecta se da el valor mínimo de 2, aumentando cuanto más
  bases ``sueltas'' contenga el tallo.
\item[gc\_content] $=(\T{cant(\mono{G})}+\T{cant(\mono{C})})/\mono{length3}$. Proporción de nucleótidos \mono{G} y
  \mono{C} en el tallo.
\end{description}
%
\subsubsection{Medidas de la secuencia}
%Este grupo contiene las siguientes medidas de la secuencia del pre-miRNA:
\begin{description}[style=sameline,leftmargin=3cm]
\item[length] longitud del pre-miRNA, incluyendo extremos sueltos y el
  bucle central.
\item[A, C, G, U] (x4) número de nucleótidos \mono{A}, \mono{C},
  \mono{G} y \mono{U}, respectivamente.
\item[G+C, A+U] (x2) número de nucleótidos \mono{G} y \mono{C}, y
  \mono{A} y \mono{U} respectivamente.
\item[XY] (x16) número de dinucleótidos (dos nucleótidos contiguos)
  \mono{XY}, con $\mono{X,Y}\in\{\mono{A,C,G,U}\}$. El orden es el
  siguiente: \mono{AC, AG, AU, CA, CC, CG, CU, GA, GC, GG, GU, UA, UC,
    UG, UU}.
\end{description}
%
\subsubsection{Medidas de la estructura secundaria}
%En este grupo se presentan las siguientes características relativas al
%plegado del pre-miRNA en su estructura de horquilla:
\begin{description}[style=sameline,leftmargin=3cm]
\item[MFE] Mínima Energía Libre obtenida al plegar la secuencia con
  \mono{RNAfold}.
\item[MFEI1] $={\mono{MFE}}/{(\mono{G+C})\cdot 100}$, con \mono{G+C}
  de las medidas de secuencia.
\item[MFEI4] $=\mono{MFE}/\mono{basepairs}$ con \mono{basepairs} de
  las características de triplete extra.
\item[dP] \mono{basepairs} normalizada con la longitud total
  \mono{length}.
\item[|A-U|/length] número de pares \mono{A-U} normalizado.
\item[|G-C|/length] número de pares \mono{G-C} normalizado.
\item[|G-U|/length] número de pares \mono{G-U} normalizado.
\end{description}
%
\subsection{Conjuntos de datos}
A continuación se listan los conjuntos de datos obtenidos en el armado
de la base de datos.
\begin{description}
\item[mirbase50] de \cite{xue}, contiene 1210 pre-miRNAs reales para
  diferentes especies, entre ellas 193 humanos, 112 de gallina, 207 de
  ratón, 172 de rata y 96 de arroz.
\item[updated] de \cite{xue}, contiene 39 pre-miRNAs humanos.
\item[coding] de \cite{xue}, contiene 8494 pseudo pre-miRNAs humanos.
\item[conserved-hairpin] de \cite{xue}, contiene 2444 pseudo
  pre-miRNAs humanos, aunque se conoce que algunos de ellos son
  pre-miRNAs reales. Se establece la clase para estas entradas como
  indeterminada, representada por el valor ambiguo 0.
\item[mirbase82-nr] de \cite{ng}, contiene 1985 pre-miRNAs de miRBase
  8.2 filtrados a 90\% de similaridad, para 40 especies incluyendo
  vertebrados, plantas y virus.
\item[functional-ncrna] de \cite{ng}, contiene 2657 ncRNAs
  funcionales, excepto pre-miRNAs, para varias
  especies.\item[mirbase12] de \cite{batuwita}, contiene 660
  pre-miRNAs humanos no redundantes originalmente de miRBase 12.0.
\item[other-ncrna] de \cite{batuwita}, contiene 129 ncRNAs humanos que
  no son pre-miRNAs.
\item[mirbase20] de \cite{mirbase}, incorpora 21433 pre-miRNAs reales
  que no tienen bucles múltiples de miRBase 20, para 204 especies,
  entre ellos 1801 humanos, 1121 de ratón, 423 de rata y 392 de arroz.
\end{description}
%
%
%
\end{document}

