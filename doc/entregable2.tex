\documentclass[12pt,bibliography=oldstyle,DIV=12,parskip=half-,titlepage]{scrartcl}
\include{conf/preconfig}
\include{conf/packages}
\include{conf/config}
\include{conf/comandos}
\include{conf/fuentes}
%
\addbibresource{res/bibliografia.bib}
%
\selectlanguage{spanish}
\hyphenation{micro-RNA}
\hyphenation{micro-RNAs}
\hyphenation{mi-RNA}
\hyphenation{mi-RNAs}
%
%
%
%
\addtokomafont{descriptionlabel}{\small}
\setkomafont{subject}{\LARGE\usekomafont{disposition}}
\setkomafont{title}{\normalfont\slshape}
\setkomafont{subtitle}{\LARGE\usekomafont{disposition}}
%
\begin{document}
\selectlanguage{spanish}
%
% pagina de titulo
%
\titlehead{\center\large
    Universidad Nacional del Litoral\\
    Facultad de Ingeniería y Ciencias Hídricas
}
%
%
\title{\LARGE ``Desarrollo de un clasificador de secuencias de pre-microRNA
  mediante técnicas de Inteligencia Computacional''}
\subject{Proyecto Final de Carrera\\Ingeniería en
  Informática}
\subtitle{~\\[.2ex]Informe entregable 2\\[.2ex]~}
\author{{Alumno: Mauro Javier Torrez}\and{Director: Dr. Diego H. Milone}}
%
\date{~\\[2em]\today}
%
\renewcommand*{\titlepagestyle}{empty}
%\thispagestyle{empty}
\maketitle
\setcounter{page}{1}
%
%
%
%
\section{Introducción}
En el presente informe entregable se presenta una revisión de las
actividades llevadas a cabo por el alumno tal como se ha estipulado en
la Propuesta de Proyecto Final de Carrera.  Se refiere al lector al
repositorio disponible en \url{https://github.com/maurete/pfc/}, donde
se puede consultar el código fuente y demás archivos generados durante
el desarrollo.

En un primer lugar se procedió a codificar métodos de entrenamiento y
optimización de parámetros para los clasificadores MLP y SVM.

Se generaron conjuntos de datos de entrenamiento y prueba replicando
trabajos anteriores \cite{xue} \cite{ng} \cite{batuwita}.  Se
realizaron pruebas de clasificación con estas configuraciones de datos
comparando los resultados obtenidos contra aquellos de los trabajos
originales.

\resalt{completar}
%
\section{Clasificadores}
Se codificaron métodos en lenguaje Matlab incorporando los
clasificadores MLP y SVM provistos por dicho software. A continuación
se detallan los tres clasificadores utilizados.
%
\subsection{Clasificador MLP}
Se utilizó el clasificador MLP disponible en el \emph{Neural Network
  Toolbox} del software Matlab. Se especificó en todos los casos una
topología \emph{capa de entrada} $\rightarrow$ \emph{capa oculta}
$\rightarrow$ \emph{capa de salida} \resalt{porqué?}.

Considerando el rendimiento del método durante la fase inicial de
pruebas se especificó un número máximo de épocas arbitrariamente
grande de $2\cdot10^{12}$, así como un tiempo máximo de entrenamiento
para cada prueba de 10 segundos. Se utilizó como función de
entrenamiento el método de gradiente conjugado escalado
\cite{moeller}.

Se estableció como parámetro a optimizar en este clasificador el
número de neuronas en la capa oculta.
%
\subsection{Clasificador SVM-RBF}
Se utilizó la implementación del clasificador SVM disponible en el
\emph{Bioinformatics Toolbox} del software Matlab, parametrizado para
utilizar un kernel RBF (\emph{Radial Basis Function}, Función de Base
Radial) \cite{svm}.

Se establecieron como parámetros a optimizar en este clasificador los
valores $C$ --parámetro de penalización de errores de clasificación--
y $\sigma$ --radio de la función de base radial utilizada como kernel.
%
\subsection{Clasificador SVM-LINEAR}
Al igual que para SVM-RBF, se utilizó la implementación disponible en
el \emph{Bioinformatics Toolbox} del software Matlab, en este caso
parametrizado para utilizar un kernel lineal \cite{svm}.

El kernel lineal consiste simplemente en una operación de producto
escalar, la cual no requiere ningun parámetro adicional. El único
parámetro a optimizar en este clasificador es entonces el parámetro de
penalización $C$.
%
\section{Entrenamiento y optimización de parámetros}
El entrenamiento de los clasificadores se realizó utilizando tres
configuraciones de los conjuntos de datos, denominados XUE, NG y BTW, que replican aquellos
utilizados en \cite{xue}, \cite{ng} y \cite{batuwita} respectivamente.

Considerando los conjuntos de características obtenidos en la etapa
anterior, se consideraron todas las combinaciones posibles de estos
conjuntos para cada clasificador.

En lo que sigue de esta sección se describen el método general de
entrenamiento y optimización de parámetros de los clasificadores, los
conjuntos de datos y de características, y las particularidades
consideradas en el entrenamiento de los clasificadores.
%
\subsection{Método general de entrenamiento}
Una llamada al método de entrenamiento recibe los siguientes
parámetros: clasificador a utilizar, conjunto de datos a utilizar,
combinación de características a considerar y una semilla para
inicialización de las funciones aleatorias utilizadas en el
entrenamiento.

El método general consiste en entrenar el clasificador con el conjunto
de entrenamiento y características dados, optimizar los parámetros
propios del clasificador y finalmente clasificar los datos de prueba
especificados en el conjunto de datos utilizado.

En todos los casos el entrenamiento se realiza mediante validación
cruzada de 5 particiones (\eng{5-fold cross-validation})
\cite{crossval}. Esta técnica consiste en generar 5 particiones de los
datos de entrenamiento, entrenar con cuatro de ellas y validar con la
restante, repitiendo el proceso 5 veces validando contra cada una de
las 5 particiones, y finalmente calcular el promedio de los 5
resultados de clasificación obtenidos.
%
\subsection{Optimización de parámetros}
El método de optimización de parámetros es dependiente del
clasificador utilizado. Para la evaluación del desempeño de los
clasificadores, se definen las medidas de \emph{sensibilidad},
\emph{especificidad} y \emph{precisión}
\begin{align}
  \T{SE} &= \frac{\T{\small número de entradas clasificadas
      correctamente como positivas}} {\T{\small número de entradas
      positivas en el conjunto de entrenamiento}}\\
  \T{SP} &= \frac{\T{\small número de entradas
      clasificadas correctamente como negativas}}{\T{\small número de
      entradas negativas en el conjunto de entrenamiento}}\\
  \T{P} &= \sqrt{\T{SE}\cdot\T{SP}}\,\,\T{.}
\end{align}

Para el clasificador MLP, el parámetro a optimizar es el número de
neuronas en la capa oculta. En este caso, se entrenó una vez para
cada valor del parámetro en el rango $[5,25]$, seleccionando como
óptimo aquel valor que maximiza el valor de P en promedio para las
5 particiones.

Para los clasificadores SVM-LINEAR y SVM-RBF, el método de
optimización de parámetros se codificó siguiendo un procedimiento
denominado \emph{búsqueda en la grilla} (\eng{grid-search})
\cite{hsu}: a partir de los rangos iniciales
$\log(C)=[-4,-2,\ldots,14]$ y $\log(\sigma)=[-15,-13,\ldots,15]$
(SVM-RBF), se entrenó el clasificador refinando los valores de $C$ y
$\sigma$ en las cercanías de aquellos para los cuales se obtuvieron
valores máximos de P. El refinamiento se efectuó en 4 iteraciones:
partiendo de una grilla logarítmicamente espaciada en $10^2$ se llegó
a una grilla refinada en $10^{0.25}$ con una progresión de
$10^{(2-r)}$, siendo $r$ el número de iteración.
%
\subsection{Conjuntos de datos}
Las tres configuraciones de los conjuntos de datos se presentan en
forma resumida en la tabla \ref{datasetup}, a continuación una
descripción de cada una de ellas. Las denominaciones indicadas en
negrita hacen referencia a aquellos conjuntos de datos recopilados en
la base de datos definitiva en la etapa anterior del desarrollo.
%
\begin{table}[h]
\small
  \caption{\small Configuraciones de los conjuntos de datos utilizados para las pruebas}
  \center%\sffamily
  \begin{tabular}{llrlrrrr}\toprule
Config. &
Fuente             & Clase & Especies  & Total  & Entrenamiento & Prueba  \\\midrule
\mrow{7}{*}{XUE}
& mirbase50        & +1    & humano    & 193    & 163   &  30   \\
& coding           & -1    & humano    & 8494   & 168   & 1000  \\
& conserved-hairpin& -1?   & humano    & 2444   & 0     & 2444  \\
& updated          & +1    & humano    & 39     & 0     &  39   \\
& mirbase50        & +1    & no-humano & 1017   & 0     & 1017  \\
& mirbase20        & +1    & humano    & 1265   & 0     & 1265  \\
& mirbase20        & +1    & no-humano & 11805  & 0     & 11805 \\\midrule
\mrow{7}{*}{NG}
& mirbase82        & +1    & humano    & 308    & 200   & 108   \\
& coding           & -1    & humano    & 8494   & 400   & 8094  \\
& mirbase82        & +1    & no-humano & 1677   & 0     & 1677  \\
& functional-ncrna & -1    & varias    & 2650   & 0     & 2650  \\
& mirbase20        & +1    & humano    & 1265   & 0     & 1265  \\
& mirbase20        & +1    & no-humano & 11805  & 0     & 11805 \\\midrule
\mrow{5}{*}{BTW}
& mirbase12        & +1    & humano    & 660    & 561   & 99    \\
& coding           & -1    & humano    & 8494   & 1012  & 7482  \\
& other-ncrna      & -1    & humano    & 129    & 110   & 19    \\
& mirbase20        & +1    & humano    & 1265   & 0     & 1265  \\
& mirbase20        & +1    & no-humano & 11805  & 0     & 11805 \\
\bottomrule
  \end{tabular}
  \label{datasetup}
\end{table}
%
\subsubsection{Configuración de datos XUE}
En esta configuración se replican los conjuntos de entrenamiento y
prueba utilizados en \cite{xue}: entrenamiento con 163 entradas de
humanos de \sbs{mirbase50} y 168 de \sbs{coding}, y prueba contra
\sbs{mirbase50} (30 entradas de humanos, 1017 otras especies),
\sbs{coding} (1000 entradas de humanos), \sbs{conserved-hairpin} (2444
entradas de humanos) y \sbs{updated} (39 entradas humanos).

Se prueba además el clasificador contra la base de datos positiva
\sbs{mirbase20} discriminando entre entradas pertenecientes a humanos
y a otras especies.
%
\subsubsection{Configuración de datos NG}
En esta configuración se replican los conjuntos de datos utilizados en
\cite{ng}.  Para entrenamiento se utilizan 200 entradas del conjunto
positivo \sbs{mirbase82} y 400 del conjunto negativo \sbs{coding}.

Se prueba el clasificador con las 108 entradas de humanos restantes de
\sbs{mirbase82}, 8094 de \sbs{coding}, 1677 entradas de
\sbs{mirbase82} pertenecientes a otras especies, 2650 entradas
negativas del conjunto \sbs{functional-ncrna}, además de las 13070
entradas del conjunto positivo \sbs{mirbase20} discriminando entre
humano y otras especies.
%
\subsubsection{Configuración de datos BTW}
Esta configuración se generó utilizando los conjuntos de datos en
\cite{batuwita}. Dado que en este trabajo no se especifica el número
de entradas utilizadas para entrenamiento y prueba, se especificó una
proporción de 85\% de las entradas positivas disponibles para
entrenamiento, el 15\% restante para prueba, y en el caso de las
entradas negativas se tomó 2 veces la cantidad de entradas positivas
para entrenamiento, y el resto de entradas disponibles para prueba.

Para entrenamiento se especifican 561 entradas positivas de humanos de
\sbs{mirbase12}, junto a 1012 entradas negativas de \sbs{coding} y
otras 110 entradas negativas de \sbs{other-ncrna}.

Se prueba el clasificador con las 99 entradas positivas restantes de
\sbs{mirbase12}, 7482 entradas negativas de \sbs{coding} y 19 de
\sbs{other-ncrna}, además de las 11805 entradas positivas de
\sbs{mirbase20} discriminadas entre humano y no-humano.

\subsection{Conjuntos de características}
Considerando los conjuntos de características definidos en la etapa
anterior, se generaron 15 configuraciones diferentes que abarcan todas
las combinaciones posibles. La composición de cada configuración se
muestra en la Tabla \ref{featsets}, marcando con un asterisco (*) el
conjunto incluido en la respectiva configuración.
%
\begin{table}[H]
  \caption{Configuraciones de las características.}
  \center%\sffamily
  \begin{tabular}{lccccccccccccccc}\toprule
Características / Configuración & 1& 2& 3& 4& 5& 6& 7& 8& 9&10&11&12&13&14&15\\
\midrule
Tripletes                       & *& *&  &  &  & *& *&  & *&  &  &  & *& *& *\\
Tripletes ``extra''             & *&  & *&  &  & *& *&  & *& *& *& *&  &  &  \\
Medidas de la secuencia         & *&  &  & *&  &  &  & *& *& *&  & *&  & *& *\\
Medidas estructura secundaria   & *&  &  &  & *&  & *& *&  & *& *&  & *&  & *\\
\bottomrule
  \end{tabular}
  \label{featsets}
\end{table}
%
\subsection{Particularidades consideradas durante la fase de entrenamiento}
\subsubsection{Desbalance de clases en el clasificador MLP}
Mientras que para los métodos de clasificación mediante SVM se
recomienda que la proporción de clases positivas a negativas durante
el entrenamiento sea de 1 a 2 \cite{ng}, se observó que en el
entrenamiento de un clasificador MLP esta proporción produce un
sobreentrenamiento hacia las clases negativas.

Debido a esto se procedió a generar un método adicional para el
clasificador MLP, denominado MLP-BAL, que simplemente ignora durante
el entrenamiento el exceso de entradas negativas por sobre el número
de entradas positivas.
%
\subsubsection{Conjuntos de datos para entradas con lazos múltiples}
En la generación de los conjuntos de datos en la etapa anterior se
decidió ignorar las entradas de las bases de datos originales que
contienen lazos múltiples en su estructura secundaria, ya que para
este tipo de entradas las características de tripletes y de
tripletes-extra no están definidas. Sin embargo, en los conjuntos de
datos utilizados para la generación de \sbs{mirbase82},
\sbs{mirbase12}, \sbs{functional-ncrna} y \sbs{other-ncrna}, así como
\sbs{mirbase20}, se presenta una proporción significativa de entradas
con lazos múltiples. Teniendo en cuenta estas observaciones, y en pos
de lograr una mayor fidelidad en los resultados, se generaron
conjuntos y configuraciones de datos adicionales (denotados con sufijo
-multi), los cuales contienen todas las entradas originales, aunque incorporan
únicamente las características de la secuencia y de la estructura
secundaria.

Se efectuaron entrenamientos y pruebas adicionales para las
configuraciones de datos ``NG-multi'' y ``BTW-multi'' y las
configuraciones de características posibles 4, 5 y 8.
%
\section{Pruebas y validación de los resultados}

\section{Clasificador definitivo}

\section{Interfaz de línea de comandos del método}


%% \begin{algorithm}[H]
%% %% \SetKwInput{Datos}{Datos}
%% %% \SetKwInput{Resultado}{Resultado}
%% %% \SetKwInput{Entrada}{Entrada}
%% %% \SetKwInput{Salida}{Salida}
%% %% \SetKw{KwA}{a}
%% %% \SetKw{KwDevolver}{devolver}
%% %% \SetKw{Devolver}{devolver}
%% %% \SetKwBlock{Inicio}{inicio}{fin}
%% %% \SetKwIF{SSi}{EnOtroCasoSi}{EnOtroCaso}{si}{entonces}{sin\'o, si}{sin\'o}{fin si}
%% %% \SetKwSwitch{Seleccionar}{Caso}{Otro}{seleccionar}{hacer}{caso}{sin\'o}{fin caso}{fin seleccionar}
%% %% \SetKwFor{Para}{para}{hacer}{fin para}
%% %% \SetKwFor{ParaPara}{par}{hacer en paralelo}{fin para}
%% %% \SetKwFor{EnParalelo}{para}{hacer en paralelo}{fin para}
%% %% \SetKwFor{Mientras}{mientras}{hacer}{fin mientras}
%% %% \SetKwFor{ParaCada}{para cada}{hacer}{fin para cada}
%% %% \SetKwFor{ParaTodo}{para todo}{hacer}{fin para todo}
%% %% \SetKwRepeat{Repetir}{repetir}{hasta que}
%% \SetAlgoLined
%% \Entrada{clasificador RBF, datos, $\sigma_0$, $C_0$, $R$}
%% \Resultado{$\sigma_{ni},C_{nj} | G_m(\T{Se}(\sigma_{ki},C_{kj}),\T{Sp}(\sigma_{ki},C_{kj})) = \max(G_m) \forall k,i,j$}
%% $C\leftarrow C_0$\;
%% $sigma\leftarrow\sigma_0$\;
%% \Para{$r\in [1,R]$}{ 
%% \ParaCada{$C_l, \sigma_m$}{
%% Se$_k$, Sp$_k$ $\leftarrow$ entrenar($C_l$, $\sigma_m$, datos, \ldots) \; 
%% $G_m(k)\leftarrow\sqrt{\T{Se}_k\cdot\T{Sp}_k}$
%% }
%% $G_m*\leftarrow\{G_m(k):(G_m(k)-\max(Gm(k)))<\T{tolerancia}\}$
%% }
%% \caption{How to write algorithms}
%% \end{algorithm}

%



\section{Pruebas de clasificación}

Las pruebas de clasificación se realizaron con los tres
clasificadores, para todas las combinaciones de configuraciones de los
conjuntos de datos y de los conjuntos de características.

Como medida para el rendimiento de los diferentes clasificadores se
utilizó la media geométrica entre la sensibilidad (tasa de
clasificación del conjunto de datos positivo) y la especificidad (tasa
de clasificación del conjunto de datos negativo) obtenida en cada
prueba.

Para cada cada prueba, el conjunto de datos de entrenamiento se
particionó en 5, 80\% entrenamiento y 20\% prueba (validación
cruzada), tal que cada conjunto de prueba no contenga entradas en
común con los otros 4. Se repitió el entrenamiento/validación cruzada
para las 5 particiones, y el resultado de la prueba se consideró como
la media aritmética de los 5 resultados obtenidos.

En pos de hacer que las pruebas fueran reproducibles, se utilizaron funciones pseudoaleatorias
que reciben como parámetro una \emph{semilla} para la generación de particiones
y el muestreo de las bases de datos. \resalt{explicar mejor.}


\section{Resultados de las pruebas de clasificación}
\resalt{Muy preliminar. Algunas conclusiones.}
\begin{itemize}
\item Dataset ALL: tasa muy baja para CODING. Se deberá reemplazar por otro dataset que entrene también con CODING.
\item Featureset 2 (triplet): no funciona bien para mirbase20.
\item Dataset XUE: rendimiento SVM-LINEAR igual o mejor que SVM-RBF.
\item Featureset 5 (estructura secundaria): muy buen desempeño con un vector de sólo 7 características.
\item Featureset 4 (secuencia): mejor desempeño que FS-5 únicamente en dataset ALL (que no funciona para CODING).
\item Dataset HSA: prácticamente clasifican mejor aquellos featuresets que excluyen los triplets.
\end{itemize}

\renewcommand{\bibfont}{\normalfont\footnotesize}
\printbibliography
\end{document}

